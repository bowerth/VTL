 


  <div class="row no-gutters">
    <div class="col-lg-12 col-xl-9 py-3">
            <h1 id="spark-usage_toc_using-the-vtl-spark-environment">Using the VTL Spark environment</h1> 
<section> 
 <h2 id="spark-usage_toc_loading-data-inside-apache-spark">Loading data inside Apache Spark™</h2> 
 <p>The Spark environment can create a dataset wrapping data that is available from your Spark installation. Available formats are CSV, plain text, parquet and json files.</p> 
 <p>Inside VTL, spark datasets can be referenced by using a common prefix. Since this requires characters not allowed in VTL aliases, you must always surround the alias with single quotes.</p> 
 <p>For example the following aliases:</p> 
 <div class="source"> 
  <div class="source"> 
   <pre>'spark:parquet:/home/myname/data.parquet'
'spark:csv:/home/myname/data.csv'
</pre> 
  </div> 
 </div> 
 <p>will reference two VTL datasets wrapping a Spark SQL DataFrame obtained from reading the input parquet and CSV files respectively.</p> 
</section> 
<section> 
 <h2 id="spark-usage_toc_setting-component-domains-and-roles">Setting component domains and roles</h2> 
 <p>As for non-spark VTL CSV files, all spark sources must have properly formatted field names to enable VTL to distinguish between components of different VTL domains or roles.</p> 
 <p>Please read the section on using CSV files for more information on how to format field names.</p> 
</section> 
<section> 
 <h2 id="spark-usage_toc_processing-data-inside-spark">Processing data inside Spark</h2> 
 <p>For VTL unary expressions, such as negation, if the operand dataset was loaded from Spark or is the result of a Spark action, the VTL Spark environment will try to transform the VTL expression into Spark SQL actions and wrap the results into a new VTL dataset.</p> 
 <p>The same happens for VTL binary expressions, when one of the operands is a scalar value. If instead both operands are datasets, and the left operand is a Spark dataset, the contents of the other dataset will be loaded and the computation will happen entirely within Spark.</p> 
 <p>In all other cases, the VTL engine will materialize all the operands and the computation will happen in-memory on the client machine. Note that this may cause delays if you are constantly moving data in and out of Spark.</p> 
</section>
        </div>
    <div class="d-none d-sm-none d-md-none d-lg-none d-xl-block col-xl-3">
        <div class="feedback-links">
            <ul class="nav flex-column flex-nowrap">
                <li class="nav-item">
                    <a class="nav-link" href="https://github.com/vpinna80/VTL/src\site\markdown/spark-usage.md.vm"><i class="far fa-edit" target="_blank" rel="noopener noreferrer"></i> Improve this page</a>
                </li>
            </ul>
        </div>
            <div id="m-toc-sidebar" class="d-print-none m-toc-sidebar-enabled m-toc-sidebar-expanded m-toc-sidebar-autoexpandable toc-sidebar-fixed">
                <nav id="m-toc-sidebar-nav flex-column">
                <ul class="m-nav--sidebar nav flex-column flex-nowrap">
    <li class="h1">
        <a class="nav-link" href="#spark-usage_toc_using-the-vtl-spark-environment" title="Using the VTL Spark environment">Using the VTL Spark environment</a>
    </li>
    <li class="h2">
        <a class="nav-link" href="#spark-usage_toc_loading-data-inside-apache-spark" title="Loading data inside Apache Spark™">Loading data inside Apache Spark™</a>
    </li>
    <li class="h2">
        <a class="nav-link" href="#spark-usage_toc_setting-component-domains-and-roles" title="Setting component domains and roles">Setting component domains and roles</a>
    </li>
    <li class="h2">
        <a class="nav-link" href="#spark-usage_toc_processing-data-inside-spark" title="Processing data inside Spark">Processing data inside Spark</a>
    </li>
                    </ul>
                </nav>
           </div>
    </div>
</div>
